import numpy as np
import pandas as pd
import gc  # Garbage Collector
number_of_rows = 2000000 # We are loading 2 million rows and skip the others.

def unique_columns(dataframe): # A function to drop all columns where all rows are the same.
    list_name = []
    temp = list(dataframe.nunique().values)
    for i in range(len(temp)):
        if temp[i] == dataframe.shape[0] or temp[i] == 1:
            list_name.append(dataframe.columns[i])
    print('Columns that were dropped:',list_name)
    return list_name

def get_top_features(fscore,df,model): # A function to get the features of a trained model with
    temp=[]                            # fscore greater than the fscore parameter.
    for i in range(len(model.feature_importances_)):
        if model.feature_importances_[i]>=fscore:
            temp.append(df.columns[i])
    print('Features with fscore greater than ',fscore,':',temp)
    return temp

train = pd.read_csv( '../input/train.csv' , skiprows =  lambda x: x > number_of_rows)
train.tail() 
train.drop(unique_columns(train),axis = 1,inplace = True)
train.select_dtypes(include = 'object').head()
train.OsVer = train.OsVer.apply(func = lambda x:x.replace(".","")).astype(float)
train.AppVersion = train.AppVersion.apply(func = lambda x:x.replace(".","")).astype(float)
train.EngineVersion = train.EngineVersion.apply(func = lambda x:x.replace(".","")).astype(float)
train.AvSigVersion = train.AvSigVersion.apply(func = lambda x:x.replace(".","")).astype(float)
train.drop(['Census_OSEdition'],axis = 1, inplace = True)
for column in train.select_dtypes(include = 'object').columns:
    print(column)
    train[column]=train[column].astype('category')
    train[column]=train[column].cat.codes
import seaborn as sns
correlation_matrix = train.corr()
mask = np.zeros_like(correlation_matrix)
mask[np.triu_indices_from(mask)] = True 
sns.heatmap(correlation_matrix, mask = mask)
correlation_matrix
y_train = train['HasDetections']
X_train = train.drop(['HasDetections'],axis=1)
del(train) # save some space
gc.collect()
import xgboost as xgb
from xgboost import plot_importance
xgbo = xgb.XGBClassifier()
xgbo.fit(X_train,y_train)
plot_importance(xgbo)
from matplotlib import pyplot
pyplot.bar(range(len(xgbo.feature_importances_)), xgbo.feature_importances_)
pyplot.show()
columns_to_be_used = get_top_features(fscore = 0.04 , df = X_train, model = xgbo)
del(X_train)
del(y_train)
gc.collect()
train = pd.read_csv( '../input/train.csv' , usecols = columns_to_be_used)

train.shape