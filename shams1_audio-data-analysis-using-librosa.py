import numpy as np # linear algebra

import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import os
import librosa

audio_data = '/kaggle/input/birdsong-recognition/train_audio/nutwoo/XC462016.mp3'

x , sr = librosa.load(audio_data)

print(type(x), type(sr))

print(x.shape, sr)
librosa.load(audio_data, sr=44100)
import IPython.display as ipd

ipd.Audio(audio_data)

import matplotlib.pyplot as plt

import librosa.display

plt.figure(figsize=(14, 5))

librosa.display.waveplot(x, sr=sr)
X = librosa.stft(x)

Xdb = librosa.amplitude_to_db(abs(X))

plt.figure(figsize=(14, 5))

librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')

plt.colorbar()
librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')

plt.colorbar()
sr = 22050 # sample rate

T = 5.0    # seconds

t = np.linspace(0, T, int(T*sr), endpoint=False) # time variable

x = 0.5*np.sin(2*np.pi*220*t)# pure sine wave at 220 Hz

#Playing the audio

ipd.Audio(x, rate=sr) # load a NumPy array

#Saving the audio

librosa.output.write_wav('tone_220.wav', x, sr)

import sklearn

spectral_centroids = librosa.feature.spectral_centroid(x, sr=sr)[0]

spectral_centroids.shape

# Computing the time variable for visualization

plt.figure(figsize=(12, 4))

frames = range(len(spectral_centroids))

t = librosa.frames_to_time(frames)

# Normalising the spectral centroid for visualisation

def normalize(x, axis=0):

    return sklearn.preprocessing.minmax_scale(x, axis=axis)

#Plotting the Spectral Centroid along the waveform

librosa.display.waveplot(x, sr=sr, alpha=0.4)

plt.plot(t, normalize(spectral_centroids), color='b')
spectral_rolloff = librosa.feature.spectral_rolloff(x+0.01, sr=sr)[0]

plt.figure(figsize=(12, 4))

librosa.display.waveplot(x, sr=sr, alpha=0.4)

plt.plot(t, normalize(spectral_rolloff), color='r')
spectral_bandwidth_2 = librosa.feature.spectral_bandwidth(x+0.01, sr=sr)[0]

spectral_bandwidth_3 = librosa.feature.spectral_bandwidth(x+0.01, sr=sr, p=3)[0]

spectral_bandwidth_4 = librosa.feature.spectral_bandwidth(x+0.01, sr=sr, p=4)[0]

plt.figure(figsize=(15, 9))

librosa.display.waveplot(x, sr=sr, alpha=0.4)

plt.plot(t, normalize(spectral_bandwidth_2), color='r')

plt.plot(t, normalize(spectral_bandwidth_3), color='g')

plt.plot(t, normalize(spectral_bandwidth_4), color='y')

plt.legend(('p = 2', 'p = 3', 'p = 4'))
x, sr = librosa.load(audio_data)

#Plot the signal:

plt.figure(figsize=(14, 5))

librosa.display.waveplot(x, sr=sr)

# Zooming in

n0 = 9000

n1 = 9100

plt.figure(figsize=(14, 5))

plt.plot(x[n0:n1])

plt.grid()
zero_crossings = librosa.zero_crossings(x[n0:n1], pad=False)

print(sum(zero_crossings))
fs=10

mfccs = librosa.feature.mfcc(x, sr=fs)

print(mfccs.shape)

(20, 97)

#Displaying  the MFCCs:

plt.figure(figsize=(15, 7))

librosa.display.specshow(mfccs, sr=sr, x_axis='time')
hop_length=12

chromagram = librosa.feature.chroma_stft(x, sr=sr, hop_length=hop_length)

plt.figure(figsize=(15, 5))

librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', hop_length=hop_length, cmap='coolwarm')
import cv2

import audioread

import logging

import os

import random

import time

import warnings



import librosa

import numpy as np

import pandas as pd

import soundfile as sf

import torch

import torch.nn as nn

import torch.cuda

import torch.nn.functional as F

import torch.utils.data as data



from contextlib import contextmanager

from pathlib import Path

from typing import Optional



from fastprogress import progress_bar

from sklearn.metrics import f1_score

from torchvision import models
def set_seed(seed: int = 42):

    random.seed(seed)

    np.random.seed(seed)

    os.environ["PYTHONHASHSEED"] = str(seed)

    torch.manual_seed(seed)

    torch.cuda.manual_seed(seed)  # type: ignore

    torch.backends.cudnn.deterministic = True  # type: ignore

    torch.backends.cudnn.benchmark = True  # type: ignore

    

    

def get_logger(out_file=None):

    logger = logging.getLogger()

    formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")

    logger.handlers = []

    logger.setLevel(logging.INFO)



    handler = logging.StreamHandler()

    handler.setFormatter(formatter)

    handler.setLevel(logging.INFO)

    logger.addHandler(handler)



    if out_file is not None:

        fh = logging.FileHandler(out_file)

        fh.setFormatter(formatter)

        fh.setLevel(logging.INFO)

        logger.addHandler(fh)

    logger.info("logger set up")

    return logger

    

    

@contextmanager

def timer(name: str, logger: Optional[logging.Logger] = None):

    t0 = time.time()

    msg = f"[{name}] start"

    if logger is None:

        print(msg)

    else:

        logger.info(msg)

    yield



    msg = f"[{name}] done in {time.time() - t0:.2f} s"

    if logger is None:

        print(msg)

    else:

        logger.info(msg)
logger = get_logger("main.log")

set_seed(1213)
TARGET_SR = 32000

TEST = Path("../input/birdsong-recognition/test_audio").exists()
if TEST:

    DATA_DIR = Path("../input/birdsong-recognition/")

else:

    # dataset created by @shonenkov, thanks!

    DATA_DIR = Path("../input/birdcall-check/")

    



test = pd.read_csv(DATA_DIR / "test.csv")

test_audio = DATA_DIR / "test_audio"





test.head()
sub = pd.read_csv("../input/birdsong-recognition/sample_submission.csv")

sub.to_csv("submission.csv", index=False)  # this will be overwritten if everything goes well
class ResNet(nn.Module):

    def __init__(self, base_model_name: str, pretrained=False,

                 num_classes=264):

        super().__init__()

        base_model = models.__getattribute__(base_model_name)(

            pretrained=pretrained)

        layers = list(base_model.children())[:-2]

        layers.append(nn.AdaptiveMaxPool2d(1))

        self.encoder = nn.Sequential(*layers)



        in_features = base_model.fc.in_features



        self.classifier = nn.Sequential(

            nn.Linear(in_features, 1024), nn.ReLU(), nn.Dropout(p=0.2),

            nn.Linear(1024, 1024), nn.ReLU(), nn.Dropout(p=0.2),

            nn.Linear(1024, num_classes))



    def forward(self, x):

        batch_size = x.size(0)

        x = self.encoder(x).view(batch_size, -1)

        x = self.classifier(x)

        multiclass_proba = F.softmax(x, dim=1)

        multilabel_proba = F.sigmoid(x)

        return {

            "logits": x,

            "multiclass_proba": multiclass_proba,

            "multilabel_proba": multilabel_proba

        }
model_config = {

    "base_model_name": "resnet50",

    "pretrained": False,

    "num_classes": 264

}



melspectrogram_parameters = {

    "n_mels": 128,

    "fmin": 20,

    "fmax": 16000

}



weights_path = "../input/birdcall-resnet50-init-weights/best.pth"
BIRD_CODE = {

    'aldfly': 0, 'ameavo': 1, 'amebit': 2, 'amecro': 3, 'amegfi': 4,

    'amekes': 5, 'amepip': 6, 'amered': 7, 'amerob': 8, 'amewig': 9,

    'amewoo': 10, 'amtspa': 11, 'annhum': 12, 'astfly': 13, 'baisan': 14,

    'baleag': 15, 'balori': 16, 'banswa': 17, 'barswa': 18, 'bawwar': 19,

    'belkin1': 20, 'belspa2': 21, 'bewwre': 22, 'bkbcuc': 23, 'bkbmag1': 24,

    'bkbwar': 25, 'bkcchi': 26, 'bkchum': 27, 'bkhgro': 28, 'bkpwar': 29,

    'bktspa': 30, 'blkpho': 31, 'blugrb1': 32, 'blujay': 33, 'bnhcow': 34,

    'boboli': 35, 'bongul': 36, 'brdowl': 37, 'brebla': 38, 'brespa': 39,

    'brncre': 40, 'brnthr': 41, 'brthum': 42, 'brwhaw': 43, 'btbwar': 44,

    'btnwar': 45, 'btywar': 46, 'buffle': 47, 'buggna': 48, 'buhvir': 49,

    'bulori': 50, 'bushti': 51, 'buwtea': 52, 'buwwar': 53, 'cacwre': 54,

    'calgul': 55, 'calqua': 56, 'camwar': 57, 'cangoo': 58, 'canwar': 59,

    'canwre': 60, 'carwre': 61, 'casfin': 62, 'caster1': 63, 'casvir': 64,

    'cedwax': 65, 'chispa': 66, 'chiswi': 67, 'chswar': 68, 'chukar': 69,

    'clanut': 70, 'cliswa': 71, 'comgol': 72, 'comgra': 73, 'comloo': 74,

    'commer': 75, 'comnig': 76, 'comrav': 77, 'comred': 78, 'comter': 79,

    'comyel': 80, 'coohaw': 81, 'coshum': 82, 'cowscj1': 83, 'daejun': 84,

    'doccor': 85, 'dowwoo': 86, 'dusfly': 87, 'eargre': 88, 'easblu': 89,

    'easkin': 90, 'easmea': 91, 'easpho': 92, 'eastow': 93, 'eawpew': 94,

    'eucdov': 95, 'eursta': 96, 'evegro': 97, 'fiespa': 98, 'fiscro': 99,

    'foxspa': 100, 'gadwal': 101, 'gcrfin': 102, 'gnttow': 103, 'gnwtea': 104,

    'gockin': 105, 'gocspa': 106, 'goleag': 107, 'grbher3': 108, 'grcfly': 109,

    'greegr': 110, 'greroa': 111, 'greyel': 112, 'grhowl': 113, 'grnher': 114,

    'grtgra': 115, 'grycat': 116, 'gryfly': 117, 'haiwoo': 118, 'hamfly': 119,

    'hergul': 120, 'herthr': 121, 'hoomer': 122, 'hoowar': 123, 'horgre': 124,

    'horlar': 125, 'houfin': 126, 'houspa': 127, 'houwre': 128, 'indbun': 129,

    'juntit1': 130, 'killde': 131, 'labwoo': 132, 'larspa': 133, 'lazbun': 134,

    'leabit': 135, 'leafly': 136, 'leasan': 137, 'lecthr': 138, 'lesgol': 139,

    'lesnig': 140, 'lesyel': 141, 'lewwoo': 142, 'linspa': 143, 'lobcur': 144,

    'lobdow': 145, 'logshr': 146, 'lotduc': 147, 'louwat': 148, 'macwar': 149,

    'magwar': 150, 'mallar3': 151, 'marwre': 152, 'merlin': 153, 'moublu': 154,

    'mouchi': 155, 'moudov': 156, 'norcar': 157, 'norfli': 158, 'norhar2': 159,

    'normoc': 160, 'norpar': 161, 'norpin': 162, 'norsho': 163, 'norwat': 164,

    'nrwswa': 165, 'nutwoo': 166, 'olsfly': 167, 'orcwar': 168, 'osprey': 169,

    'ovenbi1': 170, 'palwar': 171, 'pasfly': 172, 'pecsan': 173, 'perfal': 174,

    'phaino': 175, 'pibgre': 176, 'pilwoo': 177, 'pingro': 178, 'pinjay': 179,

    'pinsis': 180, 'pinwar': 181, 'plsvir': 182, 'prawar': 183, 'purfin': 184,

    'pygnut': 185, 'rebmer': 186, 'rebnut': 187, 'rebsap': 188, 'rebwoo': 189,

    'redcro': 190, 'redhea': 191, 'reevir1': 192, 'renpha': 193, 'reshaw': 194,

    'rethaw': 195, 'rewbla': 196, 'ribgul': 197, 'rinduc': 198, 'robgro': 199,

    'rocpig': 200, 'rocwre': 201, 'rthhum': 202, 'ruckin': 203, 'rudduc': 204,

    'rufgro': 205, 'rufhum': 206, 'rusbla': 207, 'sagspa1': 208, 'sagthr': 209,

    'savspa': 210, 'saypho': 211, 'scatan': 212, 'scoori': 213, 'semplo': 214,

    'semsan': 215, 'sheowl': 216, 'shshaw': 217, 'snobun': 218, 'snogoo': 219,

    'solsan': 220, 'sonspa': 221, 'sora': 222, 'sposan': 223, 'spotow': 224,

    'stejay': 225, 'swahaw': 226, 'swaspa': 227, 'swathr': 228, 'treswa': 229,

    'truswa': 230, 'tuftit': 231, 'tunswa': 232, 'veery': 233, 'vesspa': 234,

    'vigswa': 235, 'warvir': 236, 'wesblu': 237, 'wesgre': 238, 'weskin': 239,

    'wesmea': 240, 'wessan': 241, 'westan': 242, 'wewpew': 243, 'whbnut': 244,

    'whcspa': 245, 'whfibi': 246, 'whtspa': 247, 'whtswi': 248, 'wilfly': 249,

    'wilsni1': 250, 'wiltur': 251, 'winwre3': 252, 'wlswar': 253, 'wooduc': 254,

    'wooscj2': 255, 'woothr': 256, 'y00475': 257, 'yebfly': 258, 'yebsap': 259,

    'yehbla': 260, 'yelwar': 261, 'yerwar': 262, 'yetvir': 263

}



INV_BIRD_CODE = {v: k for k, v in BIRD_CODE.items()}
def mono_to_color(X: np.ndarray,

                  mean=None,

                  std=None,

                  norm_max=None,

                  norm_min=None,

                  eps=1e-6):

    """

    Code from https://www.kaggle.com/daisukelab/creating-fat2019-preprocessed-data

    """

    # Stack X as [X,X,X]

    X = np.stack([X, X, X], axis=-1)



    # Standardize

    mean = mean or X.mean()

    X = X - mean

    std = std or X.std()

    Xstd = X / (std + eps)

    _min, _max = Xstd.min(), Xstd.max()

    norm_max = norm_max or _max

    norm_min = norm_min or _min

    if (_max - _min) > eps:

        # Normalize to [0, 255]

        V = Xstd

        V[V < norm_min] = norm_min

        V[V > norm_max] = norm_max

        V = 255 * (V - norm_min) / (norm_max - norm_min)

        V = V.astype(np.uint8)

    else:

        # Just zero

        V = np.zeros_like(Xstd, dtype=np.uint8)

    return V





class TestDataset(data.Dataset):

    def __init__(self, df: pd.DataFrame, clip: np.ndarray,

                 img_size=224, melspectrogram_parameters={}):

        self.df = df

        self.clip = clip

        self.img_size = img_size

        self.melspectrogram_parameters = melspectrogram_parameters

        

    def __len__(self):

        return len(self.df)

    

    def __getitem__(self, idx: int):

        SR = 32000

        sample = self.df.loc[idx, :]

        site = sample.site

        row_id = sample.row_id

        

        if site == "site_3":

            y = self.clip.astype(np.float32)

            len_y = len(y)

            start = 0

            end = SR * 5

            images = []

            while len_y > start:

                y_batch = y[start:end].astype(np.float32)

                if len(y_batch) != (SR * 5):

                    break

                start = end

                end = end + SR * 5

                

                melspec = librosa.feature.melspectrogram(y_batch,

                                                         sr=SR,

                                                         **self.melspectrogram_parameters)

                melspec = librosa.power_to_db(melspec).astype(np.float32)

                image = mono_to_color(melspec)

                height, width, _ = image.shape

                image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))

                image = np.moveaxis(image, 2, 0)

                image = (image / 255.0).astype(np.float32)

                images.append(image)

            images = np.asarray(images)

            return images, row_id, site

        else:

            end_seconds = int(sample.seconds)

            start_seconds = int(end_seconds - 5)

            

            start_index = SR * start_seconds

            end_index = SR * end_seconds

            

            y = self.clip[start_index:end_index].astype(np.float32)



            melspec = librosa.feature.melspectrogram(y, sr=SR, **self.melspectrogram_parameters)

            melspec = librosa.power_to_db(melspec).astype(np.float32)



            image = mono_to_color(melspec)

            height, width, _ = image.shape

            image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))

            image = np.moveaxis(image, 2, 0)

            image = (image / 255.0).astype(np.float32)



            return image, row_id, site
def get_model(config: dict, weights_path: str):

    model = ResNet(**config)

    checkpoint = torch.load(weights_path)

    model.load_state_dict(checkpoint["model_state_dict"])

    device = torch.device("cuda")

    model.to(device)

    model.eval()

    return model
def prediction_for_clip(test_df: pd.DataFrame, 

                        clip: np.ndarray, 

                        model: ResNet, 

                        mel_params: dict, 

                        threshold=0.55):



    dataset = TestDataset(df=test_df, 

                          clip=clip,

                          img_size=224,

                          melspectrogram_parameters=mel_params)

    loader = data.DataLoader(dataset, batch_size=1, shuffle=False)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    

    model.eval()

    prediction_dict = {}

    for image, row_id, site in progress_bar(loader):

        site = site[0]

        row_id = row_id[0]

        if site in {"site_1", "site_2"}:

            image = image.to(device)



            with torch.no_grad():

                prediction = model(image)

                proba = prediction["multilabel_proba"].detach().cpu().numpy().reshape(-1)



            events = proba >= threshold

            labels = np.argwhere(events).reshape(-1).tolist()



        else:

            # to avoid prediction on large batch

            image = image.squeeze(0)

            batch_size = 16

            whole_size = image.size(0)

            if whole_size % batch_size == 0:

                n_iter = whole_size // batch_size

            else:

                n_iter = whole_size // batch_size + 1

                

            all_events = set()

            for batch_i in range(n_iter):

                batch = image[batch_i * batch_size:(batch_i + 1) * batch_size]

                if batch.ndim == 3:

                    batch = batch.unsqueeze(0)



                batch = batch.to(device)

                with torch.no_grad():

                    prediction = model(batch)

                    proba = prediction["multilabel_proba"].detach().cpu().numpy()

                    

                events = proba >= threshold

                for i in range(len(events)):

                    event = events[i, :]

                    labels = np.argwhere(event).reshape(-1).tolist()

                    for label in labels:

                        all_events.add(label)

                        

            labels = list(all_events)

        if len(labels) == 0:

            prediction_dict[row_id] = "nocall"

        else:

            labels_str_list = list(map(lambda x: INV_BIRD_CODE[x], labels))

            label_string = " ".join(labels_str_list)

            prediction_dict[row_id] = label_string

    return prediction_dict
def prediction(test_df: pd.DataFrame,

               test_audio: Path,

               model_config: dict,

               mel_params: dict,

               weights_path: str,

               threshold=0.5):

    model = get_model(model_config, weights_path)

    unique_audio_id = test_df.audio_id.unique()



    warnings.filterwarnings("ignore")

    prediction_dfs = []

    for audio_id in unique_audio_id:

        with timer(f"Loading {audio_id}", logger):

            clip, _ = librosa.load(test_audio / (audio_id + ".mp3"),

                                   sr=TARGET_SR,

                                   mono=True,

                                   res_type="kaiser_fast")

        

        test_df_for_audio_id = test_df.query(

            f"audio_id == '{audio_id}'").reset_index(drop=True)

        with timer(f"Prediction on {audio_id}", logger):

            prediction_dict = prediction_for_clip(test_df_for_audio_id,

                                                  clip=clip,

                                                  model=model,

                                                  mel_params=mel_params,

                                                  threshold=threshold)

        row_id = list(prediction_dict.keys())

        birds = list(prediction_dict.values())

        prediction_df = pd.DataFrame({

            "row_id": row_id,

            "birds": birds

        })

        prediction_dfs.append(prediction_df)

    

    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)

    return prediction_df
submission = prediction(test_df=test,

                        test_audio=test_audio,

                        model_config=model_config,

                        mel_params=melspectrogram_parameters,

                        weights_path=weights_path,

                        threshold=0.85)

submission.to_csv("submission.csv", index=False)
submission